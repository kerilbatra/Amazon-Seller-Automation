{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c54c05-c17a-4241-b9d7-d3588f66f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sp_api.api import ReportsV2\n",
    "from sp_api.api import Finances\n",
    "from sp_api.base.reportTypes import ReportType\n",
    "from sp_api.base import Marketplaces\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import pytz\n",
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "import io\n",
    "import os\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7280322-6e02-43b2-94a0-6e61ff48eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Herbion UK\n",
    "refresh_token = #\"Refresh Token Obtained From Amazon Seller Portal\"\n",
    "\n",
    "# Define the timezone for Europe/London\n",
    "uk_time = pytz.timezone('Europe/London')\n",
    "\n",
    "# Get today's date in the Europe/London timezone\n",
    "today = datetime.now(uk_time)\n",
    "\n",
    "# Subtract two days from today's date\n",
    "specific_date = today - timedelta(days=2)\n",
    "\n",
    "# Localize the specific date to the Europe/London timezone\n",
    "uk_specific_date = specific_date.replace(tzinfo=uk_time)\n",
    "\n",
    "# Define the start and end time for the entire date in Europe/London Time\n",
    "uk_data_start_time = uk_specific_date.replace(hour=0, minute=0, second=0, microsecond=0).isoformat()\n",
    "uk_data_end_time = uk_specific_date.replace(hour=23, minute=59, second=59, microsecond=999999).isoformat()\n",
    "\n",
    "# UK marketplace\n",
    "marketplace_uk = Marketplaces.UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03413407-2e35-49c3-8f46-45fc3a0de860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UK Credentials:\n",
    "#client_id = 'PASTE YOUR CLIENT ID CREDENTIAL HERE'\n",
    "#client_secret = 'PASTE YOUR CLIENT SECRET CREDENTIAL HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488efa6-f911-4411-8ff8-a8499dbea6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finance_api(refresh_token, date_start_time, date_end_time, marketplace):\n",
    "    credentials = dict(\n",
    "    refresh_token= refresh_token, \n",
    "    lwa_app_id=client_id,  # From Seller Central, named CLIENT IDENTIFIER on website.\n",
    "    lwa_client_secret=client_secret,  # From Seller Central, named CLIENT SECRET on website.\n",
    "    )\n",
    "    \n",
    "    def fetch_financial_events(finances, date_start_time, date_end_time):\n",
    "        financial_event_data = []\n",
    "        next_token = None\n",
    "        \n",
    "        while True:\n",
    "            # Make API call to list financial events\n",
    "            if next_token:\n",
    "                res = finances.list_financial_events(\n",
    "                    PostedAfter=date_start_time,\n",
    "                    PostedBefore=date_end_time,\n",
    "                    NextToken=next_token\n",
    "                )\n",
    "            else:\n",
    "                res = finances.list_financial_events(\n",
    "                    PostedAfter=date_start_time,\n",
    "                    PostedBefore=date_end_time\n",
    "                )\n",
    "            \n",
    "            # Extract payload from the response\n",
    "            payload = res.payload\n",
    "            \n",
    "            # Check if FinancialEvents exist in payload\n",
    "            if 'FinancialEvents' in payload:\n",
    "                financial_events = payload['FinancialEvents']\n",
    "                \n",
    "                # Extract shipment events details\n",
    "                if 'ShipmentEventList' in financial_events:\n",
    "                    for shipment_event in financial_events['ShipmentEventList']:\n",
    "                        amazon_order_id = shipment_event.get('AmazonOrderId', '')\n",
    "                        seller_order_id = shipment_event.get('SellerOrderId', '')\n",
    "                        marketplace_name = shipment_event.get('MarketplaceName', '')\n",
    "                        posted_date = shipment_event.get('PostedDate', '')\n",
    "                        \n",
    "                        for item in shipment_event.get('ShipmentItemList', []):\n",
    "                            seller_sku = item.get('SellerSKU', '')\n",
    "                            order_item_id = item.get('OrderItemId', '')\n",
    "                            quantity_shipped = item.get('QuantityShipped', 0)\n",
    "                            \n",
    "                            charges = {}\n",
    "                            currency_code = None\n",
    "                            \n",
    "                            # Process item charges if available\n",
    "                            if 'ItemChargeList' in item:\n",
    "                                for charge in item['ItemChargeList']:\n",
    "                                    charge_type = charge.get('ChargeType', '')\n",
    "                                    charge_amount = charge.get('ChargeAmount', {}).get('CurrencyAmount', 0)\n",
    "                                    currency_code = charge.get('ChargeAmount', {}).get('CurrencyCode', '')\n",
    "                                    \n",
    "                                    # Add charge amount to the corresponding charge type column\n",
    "                                    charges[charge_type] = charge_amount\n",
    "                            \n",
    "                            # Process item fees if available\n",
    "                            if 'ItemFeeList' in item:\n",
    "                                for fee in item['ItemFeeList']:\n",
    "                                    fee_type = fee.get('FeeType', '')\n",
    "                                    fee_amount = fee.get('FeeAmount', {}).get('CurrencyAmount', 0)\n",
    "                                    if currency_code is None:\n",
    "                                        currency_code = fee.get('FeeAmount', {}).get('CurrencyCode', '')\n",
    "                                    \n",
    "                                    # Add fee amount to the corresponding fee type column\n",
    "                                    charges[fee_type] = fee_amount\n",
    "                            \n",
    "                            # Process promotions if available\n",
    "                            if 'PromotionList' in item:\n",
    "                                for promotion in item['PromotionList']:\n",
    "                                    promotion_type = promotion.get('PromotionType', '')\n",
    "                                    promotion_amount = promotion.get('PromotionAmount', {}).get('CurrencyAmount', 0)\n",
    "                                    if currency_code is None:\n",
    "                                        currency_code = promotion.get('PromotionAmount', {}).get('CurrencyCode', '')\n",
    "                                    \n",
    "                                    # Add promotion amount to the corresponding promotion type column\n",
    "                                    charges[promotion_type] = promotion_amount\n",
    "                            \n",
    "                            # Append the extracted data to the list\n",
    "                            financial_event_data.append({\n",
    "                                'AmazonOrderId': amazon_order_id,\n",
    "                                'SellerOrderId': seller_order_id,\n",
    "                                'MarketplaceName': marketplace_name,\n",
    "                                'PostedDate': posted_date,\n",
    "                                'SellerSKU': seller_sku,\n",
    "                                'OrderItemId': order_item_id,\n",
    "                                'QuantityShipped': quantity_shipped,\n",
    "                                'CurrencyCode': currency_code,\n",
    "                                **charges\n",
    "                            })\n",
    "            \n",
    "            # Check for next token to continue pagination\n",
    "            next_token = payload.get('NextToken')\n",
    "            if not next_token:\n",
    "                break  # No more pages\n",
    "            \n",
    "        return financial_event_data\n",
    "        \n",
    "    if marketplace == refresh_token:\n",
    "        finances = Finances(credentials=credentials)\n",
    "    else:\n",
    "        finances = Finances(credentials=credentials, marketplace=marketplace) \n",
    "    \n",
    "    # Fetch financial events data with pagination\n",
    "    financial_event_data = fetch_financial_events(finances, date_start_time, date_end_time)\n",
    "    \n",
    "    # Convert the list to a DataFrame\n",
    "    financial_events_df = pd.DataFrame(financial_event_data)\n",
    "\n",
    "    try:\n",
    "        if len(financial_events_df) != 0:\n",
    "            result = financial_events_df.pivot_table(index=['AmazonOrderId', 'SellerOrderId', 'MarketplaceName', 'PostedDate',\n",
    "                                                            'SellerSKU', 'OrderItemId'], values=['QuantityShipped', 'Principal', 'Tax', 'GiftWrap', 'GiftWrapTax', 'GiftwrapChargeback',\n",
    "                                                                                                 'ShippingCharge', 'ShippingTax', 'FBAPerUnitFulfillmentFee', 'Commission', \n",
    "                                                                                                 'ShippingChargeback'], aggfunc='sum').reset_index()\n",
    "            return result\n",
    "    except:\n",
    "        if len(financial_events_df) != 0:\n",
    "            result = financial_events_df.pivot_table(index=['AmazonOrderId', 'SellerOrderId', 'MarketplaceName', 'PostedDate',\n",
    "                                                            'SellerSKU', 'OrderItemId'], values=['QuantityShipped', 'Principal', 'Tax', 'GiftWrap', 'GiftWrapTax',\n",
    "                                                                                                 'ShippingCharge', 'ShippingTax', 'FBAPerUnitFulfillmentFee', 'Commission', \n",
    "                                                                                                 'ShippingChargeback'], aggfunc='sum').reset_index()\n",
    "            return result\n",
    "        \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcb7be-44ca-4ada-b0a9-a872aea19b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Europe (Spain, UK, France, Belgium, Netherlands, Germany, Italy, Sweden, South Africa,\n",
    "        #Poland, Saudi Arabia, Egypt, Turkey, United Arab Emirates, and India marketplaces)\n",
    "url_europe = \"https://sellingpartnerapi-eu.amazon.com/orders/v0/orders/{}/orderItems\"\n",
    "url_europe1 = \"https://sellingpartnerapi-eu.amazon.com/orders/v0/orders/{}/address\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcff6f-7b8c-4dbc-ae0a-fc2c1ee26b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_order(orders_df, refresh_token, base_url, base_url1, order_ids, batch_size):\n",
    "\n",
    "    credentials = dict(\n",
    "        refresh_token= refresh_token,  # From Seller central under Authorise -> Refresh Token\n",
    "        lwa_app_id= client_id,  # From Seller Central, named CLIENT IDENTIFIER on website.\n",
    "        lwa_client_secret= client_secret,  # From Seller Central, named CLIENT SECRET on website.\n",
    "    )\n",
    "    \n",
    "    # Function to get access token\n",
    "    def get_access_token(credentials):\n",
    "        url = \"https://api.amazon.com/auth/o2/token\"\n",
    "        payload = {\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "            \"client_id\": credentials[\"lwa_app_id\"],\n",
    "            \"client_secret\": credentials[\"lwa_client_secret\"],\n",
    "            \"refresh_token\": credentials[\"refresh_token\"]\n",
    "        }\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded;charset=UTF-8\"\n",
    "        }\n",
    "        response = requests.post(url, data=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"access_token\"]\n",
    "    \n",
    "    # Get access token\n",
    "    access_token = get_access_token(credentials)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fetch_order_list_items(order_ids_batch, access_token):\n",
    "        #base_url = \"https://sellingpartnerapi-fe.amazon.com/orders/v0/orders/{}/orderItems\"\n",
    "        headers = {\n",
    "            \"x-amz-access-token\": access_token,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"User-Agent\": \"YourAppName/1.0 (Language=Python/3.8)\"\n",
    "        }\n",
    "        order_items_data = []\n",
    "    \n",
    "        for order_id in order_ids_batch:\n",
    "            retries = 0\n",
    "            while retries < 2:  # Retry at most once\n",
    "                endpoint = base_url.format(order_id)\n",
    "                response = requests.get(endpoint, headers=headers)\n",
    "    \n",
    "                if response.status_code == 200:\n",
    "                    payload = response.json().get('payload', {})\n",
    "                    order_items = payload.get('OrderItems', [])\n",
    "                    \n",
    "                    for item in order_items:\n",
    "                        # Add the order_id to each item's dictionary\n",
    "                        item['order_id'] = order_id\n",
    "                        order_items_data.append(item)  # Collecting each item in the list\n",
    "                    break  # Break the retry loop on success\n",
    "                \n",
    "                else:\n",
    "                    retries += 1\n",
    "                    if retries == 1:\n",
    "                        print(f\"Retrying for AmazonOrderId {order_id} after first failure...\")\n",
    "                        time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "                    else:\n",
    "                        print(f\"Failed to fetch orderListItems for AmazonOrderId {order_id} after retrying: {response.status_code}\")\n",
    "                        print(response.json())\n",
    "                        break\n",
    "            \n",
    "            # Add a 0.5-second delay after each order ID request\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        return order_items_data\n",
    "    \n",
    "    def fetch_order_list_items_in_batches(order_ids, batch_size, access_token):\n",
    "        order_items_data = []\n",
    "        num_batches = (len(order_ids) // batch_size) + 1\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(order_ids))\n",
    "            order_ids_batch = order_ids[start_idx:end_idx]\n",
    "    \n",
    "            batch_order_items = fetch_order_list_items(order_ids_batch, access_token)\n",
    "            order_items_data.extend(batch_order_items)\n",
    "            \n",
    "            print(f\"Batch {i} processed.\")\n",
    "            \n",
    "            # Add a delay of 10 seconds after each batch\n",
    "            if i < num_batches - 1:  # No delay after the last batch\n",
    "                time.sleep(10)\n",
    "            \n",
    "        return order_items_data\n",
    "    \n",
    "    # Collect all AmazonOrderId's into a list\n",
    "    #order_ids = orders_df['AmazonOrderId'].unique().tolist()\n",
    "    #batch_size = 20\n",
    "    order_items = fetch_order_list_items_in_batches(order_ids, batch_size, access_token)\n",
    "    print('Completed batch process')\n",
    "    \n",
    "    # Flatten the nested dictionaries\n",
    "    def flatten_order_item(item):\n",
    "        flattened_item = {}\n",
    "        for key, value in item.items():\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key, sub_value in value.items():\n",
    "                    flattened_item[f\"{key}.{sub_key}\"] = sub_value\n",
    "            elif isinstance(value, list):\n",
    "                flattened_item[key] = ', '.join(value)\n",
    "            else:\n",
    "                flattened_item[key] = value\n",
    "        return flattened_item\n",
    "    \n",
    "    flattened_order_items = [flatten_order_item(item) for item in order_items]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    order_items_df = pd.DataFrame(flattened_order_items)\n",
    "    # Replace NaN with 0\n",
    "    order_items_df.fillna(0, inplace=True)\n",
    "    \n",
    "    def fetch_order_address(order_id, access_token):\n",
    "        #base_url = \"https://sellingpartnerapi-fe.amazon.com/orders/v0/orders/{}/address\"\n",
    "        headers = {\n",
    "            \"x-amz-access-token\": access_token,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"User-Agent\": \"YourAppName/1.0 (Language=Python/3.8)\"\n",
    "        }\n",
    "        retries = 0\n",
    "        while retries < 2:  # Retry at most once\n",
    "            endpoint = base_url1.format(order_id)\n",
    "            response = requests.get(endpoint, headers=headers)\n",
    "    \n",
    "            if response.status_code == 200:\n",
    "                payload = response.json().get('payload', {})\n",
    "                return {\n",
    "                    \"order_id\": order_id,\n",
    "                    \"ShippingAddress\": payload.get('ShippingAddress', {})\n",
    "                }\n",
    "            else:\n",
    "                retries += 1\n",
    "                if retries == 1:\n",
    "                    print(f\"Retrying for AmazonOrderId {order_id} after first failure...\")\n",
    "                    time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "                else:\n",
    "                    print(f\"Failed to fetch order address for AmazonOrderId {order_id} after retrying: {response.status_code}\")\n",
    "                    print(response.json())\n",
    "                    return {\"order_id\": order_id, \"ShippingAddress\": {}}\n",
    "            # Add a 0.3-second delay after each order ID request\n",
    "            time.sleep(0.3)\n",
    "    \n",
    "    \n",
    "    def fetch_order_addresses_in_batches(order_ids, batch_size, access_token):\n",
    "        order_addresses_data = []\n",
    "        num_batches = (len(order_ids) // batch_size) + 1\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(order_ids))\n",
    "            order_ids_batch = order_ids[start_idx:end_idx]\n",
    "    \n",
    "            for order_id in order_ids_batch:\n",
    "                order_address = fetch_order_address(order_id, access_token)\n",
    "                order_addresses_data.append(order_address)\n",
    "            \n",
    "            print(f\"Batch {i} processed.\")\n",
    "            \n",
    "            # Add a delay of 10 seconds after each batch\n",
    "            if i < num_batches - 1:  # No delay after the last batch\n",
    "                time.sleep(10)\n",
    "            \n",
    "        return order_addresses_data\n",
    "    \n",
    "    # Collect all AmazonOrderId's into a list\n",
    "    #order_ids = orders_df['AmazonOrderId'].unique().tolist()\n",
    "    #batch_size = 20\n",
    "    # Fetch order addresses in batches\n",
    "    order_addresses = fetch_order_addresses_in_batches(order_ids, batch_size, access_token)\n",
    "    print('Completed Batch1 Process')\n",
    "\n",
    "    \n",
    "    # Flatten the nested dictionaries\n",
    "    def flatten_order_item(item):\n",
    "        flattened_item = {}\n",
    "        for key, value in item.items():\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key, sub_value in value.items():\n",
    "                    flattened_item[f\"{key}.{sub_key}\"] = sub_value\n",
    "            elif isinstance(value, list):\n",
    "                flattened_item[key] = ', '.join(value)\n",
    "            else:\n",
    "                flattened_item[key] = value\n",
    "        return flattened_item\n",
    "    \n",
    "    flattened_order_address = [flatten_order_item(item) for item in order_addresses]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    order_addresses_df = pd.DataFrame(flattened_order_address)\n",
    "    # Replace NaN with 0\n",
    "    order_addresses_df.fillna(0, inplace=True)\n",
    "    \n",
    "    #merging orderdetail with orderaddress\n",
    "    merged_df = pd.merge(order_items_df, order_addresses_df, left_on='order_id', right_on='order_id', how='left')\n",
    "    \n",
    "    #merging finance with orderdetail and orderaddress\n",
    "    final_sheet = pd.merge(\n",
    "        orders_df, \n",
    "        merged_df, \n",
    "        left_on=['AmazonOrderId', 'SellerSKU'], \n",
    "        right_on=['order_id', 'SellerSKU'], \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return final_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275061e-f370-4b1f-946f-338ebf7764cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data = finance_api(refresh_token, uk_data_start_time, uk_data_end_time, marketplace_uk)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d470769-c113-4c38-8950-f6f2bef2e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STARTING BATCH PROCESS FOR ALL COUNTRIES.\n",
    "\n",
    "#HERBION UK\n",
    "if uk_data is not None and not uk_data.empty:\n",
    "    if 'AmazonOrderId' in uk_data.columns:\n",
    "        uk_order_ids = uk_data['AmazonOrderId'].unique().tolist()\n",
    "        print('UK Order id')\n",
    "        uk_order = complete_order(uk_data, refresh_token, url_europe, url_europe1, uk_order_ids, 20)\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        # If 'AmazonOrderId' is not in the columns, pass\n",
    "        pass\n",
    "else:\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c1f39-29f8-4e56-a865-23301a5063b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_uk(df):\n",
    "    if df.empty:\n",
    "        print(\"No data available. Function will not run.\")\n",
    "        return None\n",
    "\n",
    "    cleaned_df = df.rename(columns={\n",
    "                'PostedDate': 'date/time',\n",
    "                'AmazonOrderId': 'order id',\n",
    "                'SellerSKU': 'sku',\n",
    "                'Title': 'Description',\n",
    "                'MarketplaceName': 'marketplace',\n",
    "                'QuantityOrdered': 'quantity',\n",
    "                'TaxCollection.Model': 'tax collection model',\n",
    "                'ShippingAddress.StateOrRegion' : 'order state',\n",
    "                'ShippingAddress.City' : 'order city',\n",
    "                'Principal': 'product sales',\n",
    "                'Tax': 'product sales tax',\n",
    "                'ShippingCharge': 'shipping credits',\n",
    "                'ShippingTax': 'shipping credits tax',\n",
    "                'GiftWrap': 'gift wrap credits',\n",
    "                'GiftWrapTax': 'giftwrap credits tax',\n",
    "                'PromotionDiscount.Amount': 'promotional rebates',\n",
    "                'PromotionDiscountTax.Amount': 'promotional rebates tax',\n",
    "                'Commission': 'selling fees',\n",
    "                'FBAPerUnitFulfillmentFee': 'fba fees'})\n",
    "    \n",
    "    \n",
    "    column_order = ['date/time', 'order id', 'sku', 'Description', 'marketplace', 'quantity', 'order city', \n",
    "                    'order state', 'ShippingDiscount.Amount','product sales', 'product sales tax', 'shipping credits', 'shipping credits tax', \n",
    "                    'ShippingChargeback', 'gift wrap credits', 'giftwrap credits tax','promotional rebates', 'promotional rebates tax', \n",
    "                    'selling fees', 'fba fees', 'ItemTax.Amount', 'ShippingTax.Amount']\n",
    "\n",
    "    column_order = [col for col in column_order if col in cleaned_df.columns]\n",
    "                 \n",
    "    cleaned_df = cleaned_df[column_order]\n",
    "    \n",
    "    if 'ShippingDiscount.Amount' in cleaned_df.columns:\n",
    "        cleaned_df['ShippingDiscount.Amount'] = cleaned_df['ShippingDiscount.Amount'].astype('float64')\n",
    "    cleaned_df['promotional rebates'] = cleaned_df['promotional rebates'].astype('float64')\n",
    "    cleaned_df['product sales tax'] = cleaned_df['product sales tax'].astype('float64')\n",
    "    cleaned_df['shipping credits tax'] = cleaned_df['shipping credits tax'].astype('float64')\n",
    "    cleaned_df['giftwrap credits tax'] = cleaned_df['giftwrap credits tax'].astype('float64')\n",
    "    cleaned_df['promotional rebates tax'] = cleaned_df['promotional rebates tax'].astype('float64')\n",
    "    cleaned_df['ItemTax.Amount'] = cleaned_df['ItemTax.Amount'].astype('float64')\n",
    "    if 'ShippingTax.Amount' in cleaned_df.columns:\n",
    "        cleaned_df['ShippingTax.Amount'] = cleaned_df['ShippingTax.Amount'].astype('float64')\n",
    "    \n",
    "    cleaned_df['difference'] = cleaned_df.apply(\n",
    "        lambda row: row['product sales tax'] - row['ItemTax.Amount'] \n",
    "        if row['product sales tax'] != row['ItemTax.Amount'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    # Calculate 'promotional rebates tax' by adding 'difference' to 'shipping credits tax'\n",
    "    if 'ShippingTax.Amount' in cleaned_df.columns:\n",
    "        cleaned_df['promotional rebates tax'] = cleaned_df['difference'] + cleaned_df['shipping credits tax'] - cleaned_df['ShippingTax.Amount']\n",
    "    else:\n",
    "        cleaned_df['promotional rebates tax'] = cleaned_df['difference'] + cleaned_df['shipping credits tax']\n",
    "    \n",
    "    \n",
    "    # Add ShippingChargeback to SellingFees\n",
    "    cleaned_df['fba fees'] = cleaned_df['fba fees'] + cleaned_df['ShippingChargeback']\n",
    "    \n",
    "    # Add shippingDiscountAmount to Promotional rebates\n",
    "    if 'ShippingDiscount.Amount' in cleaned_df.columns:\n",
    "        cleaned_df['promotional rebates'] = cleaned_df['promotional rebates'] + cleaned_df['ShippingDiscount.Amount']\n",
    "    \n",
    "    #drop columns\n",
    "    if 'ShippingTax.Amount' and 'ShippingDiscount.Amount' in cleaned_df.columns:\n",
    "         columns_to_drop = ['ShippingChargeback', 'ShippingDiscount.Amount', 'ItemTax.Amount', 'difference', 'ShippingTax.Amount']\n",
    "         cleaned_df = cleaned_df.drop(columns=columns_to_drop)\n",
    "    else:\n",
    "        columns_to_drop = ['ShippingChargeback', 'ItemTax.Amount', 'difference']\n",
    "        cleaned_df = cleaned_df.drop(columns=columns_to_drop)\n",
    "        \n",
    "    # Change the column data type to numeric\n",
    "    cleaned_df['product sales'] = pd.to_numeric(cleaned_df['product sales'], errors='coerce')\n",
    "        \n",
    "    # Columns to ensure negative values\n",
    "    columns_to_negative = ['promotional rebates', 'promotional rebates tax']\n",
    "    # Modify the values to be negative\n",
    "    for col in columns_to_negative:\n",
    "        cleaned_df[col] = cleaned_df[col].apply(lambda x: -abs(x))\n",
    "    \n",
    "    #columns to sum \n",
    "    columns_to_sum = ['product sales', 'product sales tax', 'shipping credits', 'shipping credits tax', 'gift wrap credits',\n",
    "                      'giftwrap credits tax', 'promotional rebates', 'promotional rebates tax', \n",
    "                      'selling fees', 'fba fees', ] \n",
    "        \n",
    "    # Sum and new column Total/\n",
    "    cleaned_df['Total'] = cleaned_df[columns_to_sum].sum(axis=1)\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "def upload_file_to_sharepoint(ctx, folder_in_sharepoint, file_content, file_name):\n",
    "    target_folder = ctx.web.get_folder_by_server_relative_url(folder_in_sharepoint)\n",
    "    ctx.load(target_folder)\n",
    "    ctx.execute_query()\n",
    "\n",
    "    target_file = target_folder.upload_file(file_name, file_content)\n",
    "    ctx.execute_query()\n",
    "    print(f'File {file_name} uploaded successfully to {folder_in_sharepoint}')\n",
    "\n",
    "try:\n",
    "    uk_order\n",
    "except NameError:\n",
    "    print(\"There is no report for this country\")\n",
    "else:\n",
    "    uk_transactions = my_uk(uk_order)\n",
    "    if uk_transactions is not None:\n",
    "        # Convert the DataFrame to a file-like object\n",
    "        output = BytesIO()\n",
    "        uk_transactions.to_excel(output, index=False)\n",
    "        output.seek(0)\n",
    "\n",
    "        # SharePoint credentials\n",
    "        sharepoint_base_url = #'URL FROM SHAREPOINT'\n",
    "        sharepoint_user = #'USERNAME'\n",
    "        sharepoint_password = #'PASSWORD'\n",
    "        folder_in_sharepoint = #'FOLDER WHERE DATA IS BEEN UPLOADED'\n",
    "        current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "        file_name = f'AmazonUK_{current_date}.xlsx'\n",
    "\n",
    "        # SharePoint authentication and upload\n",
    "        auth = AuthenticationContext(sharepoint_base_url)\n",
    "        if auth.acquire_token_for_user(sharepoint_user, sharepoint_password):\n",
    "            ctx = ClientContext(sharepoint_base_url, auth)\n",
    "            upload_file_to_sharepoint(ctx, folder_in_sharepoint, output, file_name)\n",
    "        else:\n",
    "            print(\"Authentication failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
